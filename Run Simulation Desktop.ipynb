{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c05e892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python Simulation.py 7 0 500 2 1 0.02 testrun -1.0 26278342 -0.2 Regular 3.0 0.02 0.25 0.25 20 52 0.02 2 0.25 5 140'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time as time\n",
    "import subprocess \n",
    "\n",
    "from SimulationControl import SimControl\n",
    "\n",
    "ps = {\"ImprovedSpatial\": 2,\n",
    "      \"Small_world\":0.01 ,\n",
    "      \"Scale_free\": 1, \n",
    "      \"SBlock\": 1-0.01,\n",
    "      \"Regular\": 0,}\n",
    "\n",
    "\n",
    "SimCon = SimControl()\n",
    "\n",
    "\n",
    "SimCon.params[\"k\"] = 7\n",
    "SimCon.params[\"Network_type\"] = \"Regular\"\n",
    "\n",
    "\n",
    "SimCon.params[\"Notebook\"] = 2 #1 is to save the firing data, 2 is to save the network data and firing data, 0 is for simulating on cluster\n",
    "SimCon.params[\"simtime\"] = 500\n",
    "SimCon.params[\"h\"] = 0.02\n",
    "SimCon.params[\"n\"] = 52\n",
    "SimCon.params[\"p\"] = ps[SimCon.params[\"Network_type\"]]\n",
    "SimCon.params[\"StimSites\"] = 0.25\n",
    "SimCon.params[\"StimAmplitude\"] = 5\n",
    "SimCon.params[\"StimFrequency\"] = 140\n",
    "\n",
    "SimCon.Generate_Command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7bf17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing external stimulation\r\n",
      "\n",
      "c:\\users\\catha\\desktop\\shortcuts\\python\\pynn-0.9.5\\pyNN\\neuron\\recording.py:115: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\r\n",
      "  signals = numpy.vstack((id._cell.traces[variable] for id in ids)).T\r\n",
      "C:\\Users\\catha\\anaconda3\\envs\\NeuronT\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\r\n",
      "  out=out, **kwargs)\r\n",
      "C:\\Users\\catha\\anaconda3\\envs\\NeuronT\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\r\n",
      "  ret = ret.dtype.type(ret / rcount)\r\n",
      "C:\\Users\\catha\\anaconda3\\envs\\NeuronT\\lib\\site-packages\\numpy\\core\\_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\r\n",
      "  keepdims=keepdims, where=where)\r\n",
      "C:\\Users\\catha\\anaconda3\\envs\\NeuronT\\lib\\site-packages\\numpy\\core\\_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\r\n",
      "  subok=False)\r\n",
      "C:\\Users\\catha\\anaconda3\\envs\\NeuronT\\lib\\site-packages\\numpy\\core\\_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\r\n",
      "  ret = ret.dtype.type(ret / rcount)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"Simulation.py\", line 180, in <module>\r\n",
      "    data_dict = fill_dict(STN,GPe,dt,simtime)\r\n",
      "  File \"C:\\Users\\catha\\Documents\\Research\\Models\\Study1_STN-GPe_Network_Stimulator\\additional_functions.py\", line 920, in fill_dict\r\n",
      "    \"Max CSD\": max(abs(csd)),\r\n",
      "TypeError: 'int' object is not iterable\r\n",
      "\n",
      "Time taken: 6.79\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-772855c6a392>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSimCon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GSweight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GGweight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# these params dont count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mSimCon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimCon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"h\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "p = subprocess.Popen(SimCon.Generate_Command(),stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "out, err = p.communicate()\n",
    "print(out.decode('UTF-8'))\n",
    "print(err.decode('UTF-8'))\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Time taken: {t1-t0:.2f}\")\n",
    "\n",
    "\n",
    "data = np.load(f\"B:\\SimOutput\\\\NotebookData.npy\",allow_pickle=True).item()\n",
    "netdat = np.load(f\"B:\\SimOutput\\\\NotebookNetworkData.npy\",allow_pickle=True).item()\n",
    "\n",
    "STN = data[\"STN\"]\n",
    "GPe = data[\"GPe\"]\n",
    "data_dict = data[\"data\"]\n",
    "\n",
    "STG_list = netdat[\"STG_list\"]\n",
    "GTS_list = netdat[\"GTS_list\"]\n",
    "GTG_list = netdat[\"GTG_list\"]\n",
    "graph_measures = netdat[\"graph_measures\"]\n",
    "\n",
    "#Make sure the correct data is being loaded \n",
    "for key in SimCon.params:\n",
    "    if key not in ['weight', 'GSweight', 'GGweight']: # these params dont count\n",
    "        assert SimCon.params[key] == data_dict[key]\n",
    "\n",
    "dt = SimCon.params[\"h\"]\n",
    "simtime = SimCon.params[\"simtime\"]\n",
    "\n",
    "def get_spike_trains(pop):\n",
    "    main_lis = []\n",
    "    for sp in pop.spiketrains:\n",
    "        s_lis = [ float(i) for i in sp] \n",
    "        main_lis.append(np.array(s_lis))\n",
    "\n",
    "    return main_lis\n",
    "\n",
    "low_cutoff = int(500/dt) #number of segments corresponding to first 500ms\n",
    "\n",
    "SLFP = np.array(STN.filter(name='soma(0.5).v')[0]).mean(axis=1)#(axis=1)\n",
    "GLFP = np.array(GPe.filter(name='soma(0.5).v')[0]).mean(axis=1)\n",
    "\n",
    "\n",
    "packed_dat = [{\"SLFP\": SLFP,\"GLFP\": GLFP,\n",
    "               \"STrain\":get_spike_trains(STN),\n",
    "               \"GTrain\":get_spike_trains(GPe),\n",
    "               \"Sync\":np.sqrt(data_dict['STN synchrony']*data_dict['GPe synchrony']) ,\n",
    "              \"SMean\":data_dict[\"SMean\"],\n",
    "               \"GMean\":data_dict[\"GMean\"],\n",
    "              }]\n",
    "#loc = 'dataOct21\\\\'\n",
    "netname = data_dict['Network_type']\n",
    "#name = f'S_{netname}_{n}_{data_dict[\"k\"]}_{data_dict[\"p\"]:5f}_{data_dict[\"recip\"]:.5f}.npy'\n",
    "#np.save(loc+name,packed_dat)\n",
    "recovered_dat = packed_dat[0] #np.load(loc+name,allow_pickle=True)[0]\n",
    "\n",
    "print('Lambda2: ', sorted(graph_measures['eigs'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = '#2A92F5'\n",
    "colg = '#F5352A'\n",
    "\n",
    "\n",
    "k = data_dict[\"k\"]\n",
    "netlab = {'Regular':'k-Regular',  'Small_world': 'Small World','Spatial':'Nearest Neighbour',\n",
    "          'Scale_free': 'Preferential Attachment','SBlock': 'Stochastic Block'}\n",
    "\n",
    "SLFP = recovered_dat[\"SLFP\"]\n",
    "GLFP = recovered_dat[\"GLFP\"]\n",
    "\n",
    "STrain = recovered_dat[\"STrain\"]\n",
    "GTrain = recovered_dat[\"GTrain\"]\n",
    "\n",
    "sync = float(recovered_dat[\"Sync\"])\n",
    "textstr = r'Mean $\\chi$: '+ f'{sync:>3.3f}' + f\"\\nSTN FR: {data_dict['SMean']:>6.2f} \\nGPe FR: {data_dict['GMean']:>6.2f} \" \n",
    "\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1,edgecolor='white')\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "\n",
    "infigfontsize = 15\n",
    "titlefontsize = 18\n",
    "\n",
    "ilim = 50\n",
    "\n",
    "x_axis = np.linspace(0,simtime,len(GLFP))\n",
    "\n",
    "fig,ax = plt.subplots(2,1,figsize=[14,9],sharex=True)\n",
    "#fig.suptitle(params[\"Network_type\"])\n",
    "\n",
    "for i, train in enumerate(zip(STrain,GTrain)):\n",
    "    train1 = train[0]\n",
    "    train2 = train[1]\n",
    "    if i>ilim:\n",
    "        break\n",
    "    if i==0:\n",
    "        ax[0].plot(train1, i*np.ones(len(train1)), 'o', color = cols,markersize=5, alpha=0.5, label='STN')\n",
    "        ax[0].plot(train2, i*np.ones(len(train2)), 'o', color = colg,markersize=6, alpha=0.8, label='GPe')\n",
    "    else:\n",
    "        ax[0].plot(train1, i*np.ones(len(train1)), 'o', color = cols,markersize=5, alpha=0.8)\n",
    "        ax[0].plot(train2, i*np.ones(len(train2)), 'o', color = colg,markersize=6, alpha=0.9)\n",
    "\n",
    "\n",
    "#f'{netlab[data_dict[\"Network_type\"]]} Network'\n",
    "ax[0].set_title(f'Simulation Raster Plot: k={k}',fontsize=titlefontsize)\n",
    "ax[0].set_ylabel(\"Neuron Index\",fontsize=infigfontsize)\n",
    "ax[0].set_xlim(0,700)\n",
    "ax[0].set_ylim(-1,ilim+1)\n",
    "ax[0].legend(fontsize=infigfontsize,loc='upper right',framealpha=1)\n",
    "#ax[0].legend(fontsize=16,framealpha=1,shadow = True,borderpad=0.8,loc='upper right')\n",
    "\n",
    "ax[1].plot(x_axis, SLFP, label = 'STN',color = cols, alpha=0.9)\n",
    "ax[1].plot(x_axis, GLFP, label = 'GPe',color = colg, alpha=1)\n",
    "ax[1].set_title('Average Membrane Potential',fontsize=infigfontsize)\n",
    "ax[1].set_ylabel(\"Membrane Potential (mV)\",fontsize=infigfontsize)\n",
    "ax[1].set_xlabel(\"Time (ms)\",fontsize=infigfontsize)\n",
    "ax[1].set(ylim=[-85,-30,])\n",
    "ax[1].text(0.72, 0.95, textstr, transform=ax[1].transAxes, color='k', fontsize=infigfontsize, verticalalignment='top', bbox=props)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"NewAmalgData\\\\\"+f\"{netname}_{int(k)}.npy\",recovered_dat)  \n",
    "# dat2={}\n",
    "\n",
    "# for S in [\"Spatial\",\"Small_world\",\"Scale_free\", \"SBlock\",\"Regular\"]:\n",
    "#     for K in [5,30]:\n",
    "#         dat2[(S,K)] = np.load(\"NewAmalgData\\\\\"+f\"{S}_{int(K)}.npy\",allow_pickle=True).item(0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed102ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"LFPsMarch.npy\",dat2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
